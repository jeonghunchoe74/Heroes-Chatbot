# app/services/chatbot_service.py
import os
import uuid
import logging
from typing import TypedDict, Annotated, List, Dict, Optional
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# âœ… ì¶”ê°€
from app.services.guru_service import get_guru_prompt

logger = logging.getLogger(__name__)

# ğŸ”§ LLM ì´ˆê¸°í™”
llm = ChatOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    model_name=os.getenv("OPENAI_DEFAULT_MODEL", "gpt-3.5-turbo")
)

# ğŸ“¦ ëŒ€í™” ìƒíƒœ êµ¬ì¡° ì •ì˜
class State(TypedDict):
    messages: Annotated[List, add_messages]

# ğŸ” LangGraph êµ¬ì„±
def chatbot(state: State):
    response = llm.invoke(state["messages"])
    return {"messages": [response]}

workflow = StateGraph(State)
workflow.add_node("chatbot", chatbot)
workflow.add_edge(START, "chatbot")
workflow.add_edge("chatbot", END)
graph = workflow.compile()

# ğŸ’¾ ì„¸ì…˜ë³„ ìƒíƒœ ì €ì¥ì†Œ
sessions: Dict[str, State] = {}

# ğŸ§  ì„¸ì…˜ ìƒì„± / ì¡°íšŒ
def get_or_create_session(session_id: Optional[str] = None) -> tuple[str, State]:
    if session_id and session_id in sessions:
        logger.info(f"ê¸°ì¡´ ì„¸ì…˜ ì‚¬ìš©: {session_id}")
        return session_id, sessions[session_id]

    # âœ… guru_serviceì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ (buffet.txt ì½ìŒ)
    try:
        prompt_text = get_guru_prompt("buffet")  # â† app/data/prompts/buffet.txt ë¡œë“œ
        logger.info("Buffet í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ.")
    except Exception as e:
        logger.warning(f"Buffet í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ë¬¸êµ¬ ì‚¬ìš©: {e}")
        prompt_text = (
            "ë„ˆëŠ” ì›Œë Œ ë²„í•ì´ë‹¤(êµìœ¡ìš©). ë§íˆ¬ëŠ” ì‰½ê³  í¸í•˜ê²Œ, í•œ ë‹¨ë½ 2~3ë¬¸ì¥. "
            "í‹°ì»¤Â·ê°€ê²©Â·ìˆ«ì ë‚˜ì—´Â·ì „ë¬¸ìš©ì–´Â·ë§¤ìˆ˜/ë§¤ë„ ì§€ì‹œÂ·ì´ëª¨ì§€ ê¸ˆì§€. "
            "ì„¹í„° ì´ë¦„ë§Œ ë§í•´ë¼(ì˜ˆ: ê¸ˆìœµ, ë¶€ë™ì‚°, ì‚°ì—… ìë™í™” ë“±). "
            "í•µì‹¬ì€ ì‰¬ìš´ ì‚¬ì—…, ê¾¸ì¤€í•œ ì´ìµ, ë°”ê¾¸ê¸° ì–´ë ¤ìš´ ê°•ì , ë¯¿ì„ ë§Œí•œ ìš´ì˜. "
            "ê°€ê²©ì´ ë¹„ì‹¸ë©´ ê¸°ë‹¤ë¦¬ê³  ì ë‹¹í•˜ë©´ ì˜¤ë˜ ë“¤ê³  ê°„ë‹¤."
        )

    new_session_id = str(uuid.uuid4())
    sessions[new_session_id] = {
        "messages": [SystemMessage(content=prompt_text)]
    }
    logger.info(f"ìƒˆ ì„¸ì…˜ ìƒì„±: {new_session_id}")
    return new_session_id, sessions[new_session_id]

# ğŸ’¬ GPT ì‘ë‹µ ìƒì„±
async def generate_response(user_input: str, session_id: Optional[str] = None):
    session_id, state = get_or_create_session(session_id)
    state["messages"].append(HumanMessage(content=user_input))
    result = graph.invoke({"messages": state["messages"]})
    ai_response = result["messages"][-1].content
    state["messages"] = result["messages"]
    sessions[session_id] = state
    logger.info(f"ì„¸ì…˜ {session_id} ì—…ë°ì´íŠ¸ ì™„ë£Œ (ì´ {len(state['messages'])}ê°œ ë©”ì‹œì§€)")
    return ai_response, session_id

# ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™”
def reset_session(session_id: Optional[str] = None):
    if session_id and session_id in sessions:
        del sessions[session_id]
        return f"ì„¸ì…˜ {session_id}ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
    else:
        count = len(sessions)
        sessions.clear()
        return f"ëª¨ë“  ì„¸ì…˜({count}ê°œ)ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
