# app/services/news_service.py
import time, html
from typing import List, Dict
from openai import OpenAI
from app.services.naver_news import collect_news
from app.services.preprocess import dedup_by_title_host, clean_text
from app.config import MAX_PAGES, NEWS_PER_PAGE, OPENAI_API_KEY

client = OpenAI(api_key=OPENAI_API_KEY)

GURU_NEWS_QUERY = {
    "buffett": "ìœ í‹¸ë¦¬í‹° OR ê¸ˆìœµì„œë¹„ìŠ¤ OR ì†Œì¬",  # ğŸŒ ì›Œë Œ ë²„í•    
    "lynch": "ìë™ì°¨Â·ë¶€í’ˆ OR í—¬ìŠ¤ì¼€ì–´ ì¥ë¹„Â·ì„œë¹„ìŠ¤ OR ì†Œí”„íŠ¸ì›¨ì–´Â·ì„œë¹„ìŠ¤",  # ğŸª í”¼í„° ë¦°ì¹˜
    "wood": "ë°˜ë„ì²´ OR ì—ë„ˆì§€ OR í†µì‹ ì„œë¹„ìŠ¤",  # ğŸ’» ìºì‹œ ìš°ë“œ
}


def summarize_news(guru_name: str) -> List[Dict]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ í›„ ìƒìœ„ 3ê°œ ìš”ì•½
    """
    query = GURU_NEWS_QUERY.get(guru_name.lower(), f"{guru_name} íˆ¬ì OR ì‹œì¥")
    items = collect_news(query, max_pages=1, per_page=NEWS_PER_PAGE)
    items = dedup_by_title_host(items)[:3]  # ìƒìœ„ 3ê°œë§Œ

    results = []
    for it in items:
        title = clean_text(it["title"])
        desc = clean_text(it.get("description", ""))
        link = it["link"]

        # OpenAIë¡œ ìš”ì•½ ìƒì„±
        try:
            resp = client.responses.create(
                model="gpt-4o-mini",
                input=f"ë‰´ìŠ¤ ì œëª©: {title}\në‚´ìš© ìš”ì•½(í•œ ì¤„): {desc}\ní•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì¤˜.",
                temperature=0.3,
            )
            summary = resp.output_text.strip()
        except Exception:
            summary = desc[:100] + "..."

        results.append({
            "title": title,
            "summary": summary,
            "url": link
        })
        time.sleep(0.3)
    return results
